{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOfIFqMbpl1Z",
    "outputId": "0c3ff24c-42ce-4ac6-9108-4ff44748c2fb"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql as pyspark_sql\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time_uuid\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder\\\n",
    ".appName('local')\\\n",
    ".config(\"spark.jars\", \"mysql-connector-java-8.0.30.jar\")\\\n",
    ".config('spark.jars', 'spark-cassandra-connector-assembly_2.12-3.3.0')\\\n",
    ".getOrCreate()\n",
    "\n",
    "# Bỏ giới hạn cột\n",
    "pd.set_option('display.max_columns', None)\n",
    "spark.conf.set(\"spark.sql.parquet.mergeSchema\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thông tin của MySQL db\n",
    "host = 'localhost'\n",
    "port = str(3306)\n",
    "db_name = 'study_de'\n",
    "url = 'jdbc:mysql://' + host + ':' + port + '/' + db_name\n",
    "\n",
    "driver = \"com.mysql.cj.jdbc.Driver\"\n",
    "user = 'root'\n",
    "password = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chuẩn bị data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Kết nối tới Cassandra để lấy bảng tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table='log_tracking', keyspace='study_de')\\\n",
    "    .load()\\\n",
    "    .select('create_time', col('job_id').cast(IntegerType()).cast(StringType()), 'custom_track','bid','campaign_id'\\\n",
    "            ,col('group_id').cast(IntegerType()).cast(StringType()), 'publisher_id', 'ts')\n",
    "\n",
    "# data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dùng create_time (Chuyển từ dạng uuid time -> timestamp)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uuid2ts(uuid_str):\n",
    "    my_uuid = uuid.UUID(uuid_str)\n",
    "    ts_long = time_uuid.TimeUUID(bytes=my_uuid.bytes).get_timestamp()\n",
    "    return float(ts_long)\n",
    "\n",
    "uuid2ts_udf = udf(uuid2ts, FloatType())\n",
    "\n",
    "def process_df(df):\n",
    "    df_processed = df\\\n",
    "    .withColumn('ts', from_unixtime(uuid2ts_udf('create_time')))\\\n",
    "    .select('create_time', 'ts', 'job_id','custom_track','bid','campaign_id','group_id','publisher_id')\n",
    "    return df_processed\n",
    "\n",
    "# df_processed = process_df(data)\n",
    "# df_processed.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tính toán các bảng output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bảng `click`\n",
    "def calculating_clicks(df):\n",
    "    clicks_data = df.filter(df.custom_track == 'click')\n",
    "    clicks_data = clicks_data.na.fill({'bid':0})\n",
    "    clicks_data = clicks_data.na.fill({'job_id':0})\n",
    "    clicks_data = clicks_data.na.fill({'publisher_id':0})\n",
    "    clicks_data = clicks_data.na.fill({'group_id':0})\n",
    "    clicks_data = clicks_data.na.fill({'campaign_id':0})\n",
    "    clicks_data.createOrReplaceTempView('clicks')\n",
    "    clicks_output = spark.sql(\"\"\"select job_id , date(ts) as date , hour(ts) as hour , publisher_id , campaign_id , group_id , avg(bid) as bid_set, count(*) as clicks , sum(bid) as spend_hour from clicks\n",
    "    group by job_id , date(ts) , hour(ts) , publisher_id , campaign_id , group_id \"\"\")\n",
    "    return clicks_output \n",
    "\n",
    "# clicks_output = calculating_clicks(df_processed)\n",
    "# clicks_output.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bảng `coversion`\n",
    "def calculating_conversion(df):\n",
    "    conversion_data = df.filter(df.custom_track == 'conversion')\n",
    "    conversion_data = conversion_data.na.fill({'job_id':0})\n",
    "    conversion_data = conversion_data.na.fill({'publisher_id':0})\n",
    "    conversion_data = conversion_data.na.fill({'group_id':0})\n",
    "    conversion_data = conversion_data.na.fill({'campaign_id':0})\n",
    "    conversion_data.createOrReplaceTempView('conversion')\n",
    "    conversion_output = spark.sql(\"\"\"select job_id , date(ts) as date , hour(ts) as hour , publisher_id , campaign_id , group_id , count(*) as conversions  from conversion\n",
    "    group by job_id , date(ts) , hour(ts) , publisher_id , campaign_id , group_id \"\"\")\n",
    "    return conversion_output \n",
    "\n",
    "# conversion_output = calculating_conversion(df_processed)\n",
    "# conversion_output.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bảng `qualifed`\n",
    "def calculating_qualified(df):    \n",
    "    qualified_data = df.filter(df.custom_track == 'qualified')\n",
    "    qualified_data = qualified_data.na.fill({'job_id':0})\n",
    "    qualified_data = qualified_data.na.fill({'publisher_id':0})\n",
    "    qualified_data = qualified_data.na.fill({'group_id':0})\n",
    "    qualified_data = qualified_data.na.fill({'campaign_id':0})\n",
    "    qualified_data.createOrReplaceTempView('qualified')\n",
    "    qualified_output = spark.sql(\"\"\"select job_id , date(ts) as date , hour(ts) as hour , publisher_id , campaign_id , group_id , count(*) as qualified  from qualified\n",
    "    group by job_id , date(ts) , hour(ts) , publisher_id , campaign_id , group_id \"\"\")\n",
    "    return qualified_output\n",
    "\n",
    "# qualified_output = calculating_qualified(df_processed)\n",
    "# qualified_output.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bảng `ununqualified`\n",
    "def calculating_unqualified(df):\n",
    "    unqualified_data = df.filter(df.custom_track == 'unqualified')\n",
    "    unqualified_data = unqualified_data.na.fill({'job_id':0})\n",
    "    unqualified_data = unqualified_data.na.fill({'publisher_id':0})\n",
    "    unqualified_data = unqualified_data.na.fill({'group_id':0})\n",
    "    unqualified_data = unqualified_data.na.fill({'campaign_id':0})\n",
    "    unqualified_data.createOrReplaceTempView('unqualified')\n",
    "    unqualified_output = spark.sql(\"\"\"select job_id , date(ts) as date , hour(ts) as hour , publisher_id , campaign_id , group_id , count(*) as unqualified  from unqualified\n",
    "    group by job_id , date(ts) , hour(ts) , publisher_id , campaign_id , group_id \"\"\")\n",
    "    return unqualified_output\n",
    "\n",
    "# unqualified_output = calculating_unqualified(df_processed)\n",
    "# unqualified_output.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join các bảng trên để ra kết quả\n",
    "def process_final_data(clicks_output,conversion_output,qualified_output,unqualified_output):\n",
    "    keys = ['job_id','date','hour','publisher_id','campaign_id','group_id']\n",
    "    final_data = clicks_output\\\n",
    "        .join(conversion_output, keys,'full')\\\n",
    "        .join(qualified_output, keys,'full')\\\n",
    "        .join(unqualified_output, keys,'full')\n",
    "    return final_data \n",
    "\n",
    "# final_data = process_final_data(clicks_output,conversion_output,qualified_output,unqualified_output)\n",
    "# final_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm gom các bước xử lý trên\n",
    "def process_cassandra_data(df):\n",
    "    clicks_output = calculating_clicks(df)\n",
    "    conversion_output = calculating_conversion(df)\n",
    "    qualified_output = calculating_qualified(df)\n",
    "    unqualified_output = calculating_unqualified(df)\n",
    "    final_data = process_final_data(clicks_output,conversion_output,qualified_output,unqualified_output)\n",
    "    return final_data\n",
    "\n",
    "# final_data = process_cassandra_data(df_processed)\n",
    "# final_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lấy data từ bảng `company`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_company_data():\n",
    "    sql = \"\"\"(SELECT id as job_id, company_id, group_id, campaign_id FROM job) test\"\"\"\n",
    "    company = spark.read.format('jdbc').options(url=url, driver=driver, dbtable=sql, user=user, password=password).load()\n",
    "    return company\n",
    "\n",
    "# company = retrieve_company_data()\n",
    "# company.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import data vào MySQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_to_mysql(output, db_table):\n",
    "    final_output = output.select('job_id','date','hour','publisher_id','company_id','campaign_id','group_id'\\\n",
    "        ,'unqualified','qualified','conversions','clicks','bid_set','spend_hour', 'latest_update_time')\n",
    "    final_output = final_output\\\n",
    "        .withColumnRenamed('date','dates')\\\n",
    "        .withColumnRenamed('hour','hours')\\\n",
    "        .withColumnRenamed('qualified','qualified_application')\\\n",
    "        .withColumnRenamed('unqualified','disqualified_application')\\\n",
    "        .withColumnRenamed('conversions','conversion')\\\n",
    "        .withColumn('sources', lit('Cassandra'))\n",
    "    \n",
    "    # Import vào db\n",
    "    final_output.write.format('jdbc')\\\n",
    "    .option('url', url)\\\n",
    "    .option('driver', driver)\\\n",
    "    .option('dbtable', db_table)\\\n",
    "    .option('user', user)\\\n",
    "    .option('password', password)\\\n",
    "    .mode('append').save()\n",
    "    return print('Data imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Case 1: Import data từ Cassandra db đến MySQL db, lần đầu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Định nghĩa hàm main_task để thực thi các lệnh trên**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_task():\n",
    "    print('The host is ' ,host)\n",
    "    print('The port using is ',port)\n",
    "    print('The db using is ',db_name)\n",
    "    print('-----------------------------')\n",
    "    print('Retrieving and selecting data from Cassandra')\n",
    "    print('-----------------------------')\n",
    "    df = data\\\n",
    "        .select('create_time','job_id','custom_track','bid','campaign_id','group_id','publisher_id', 'ts')\\\n",
    "        .filter(data.job_id.isNotNull())\n",
    "    df.printSchema()\n",
    "    print('-----------------------------')\n",
    "    print('Processing data from Cassandra')\n",
    "    print('-----------------------------')\n",
    "    df = process_df(df)\n",
    "    print('-----------------------------')\n",
    "    print('Getting and check newest data')\n",
    "    print('-----------------------------')\n",
    "    df = df\\\n",
    "        #.where(col('ts')>= mysql_time)\n",
    "    print('-----------------------------')\n",
    "    print('Processing Cassandra Output')\n",
    "    print('-----------------------------')\n",
    "    cassandra_output = process_cassandra_data(df)\n",
    "    print('-----------------------------')\n",
    "    print('Merge Company Data')\n",
    "    print('-----------------------------')\n",
    "    company = retrieve_company_data()\n",
    "    print('-----------------------------')\n",
    "    print('Finalizing Output')\n",
    "    print('-----------------------------')\n",
    "    final_output = cassandra_output\\\n",
    "        .join(company,'job_id','full')\\\n",
    "        .drop(company.group_id)\\\n",
    "        .drop(company.campaign_id)\\\n",
    "        .withColumn('latest_update_time', current_timestamp())\n",
    "    print('-----------------------------')\n",
    "    print('Import Output to MySQL')\n",
    "    print('-----------------------------')\n",
    "    import_to_mysql(final_output, db_table='events')\n",
    "    return print('Task Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Case 2: Import data từ Cassandra db đến MySQL db, cập nhật từng dòng data mới vào**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_task(mysql_time):\n",
    "    print('The host is ' ,host)\n",
    "    print('The port using is ',port)\n",
    "    print('The db using is ',db_name)\n",
    "    print('-----------------------------')\n",
    "    print('Retrieving and selecting data from Cassandra')\n",
    "    print('-----------------------------')\n",
    "    df = data\\\n",
    "        .select('create_time','job_id','custom_track','bid','campaign_id','group_id','publisher_id')\\\n",
    "        .filter(data.job_id.isNotNull())\n",
    "    print('-----------------------------')\n",
    "    print('Processing data from Cassandra')\n",
    "    print('-----------------------------')\n",
    "    df = process_df(df)\n",
    "    df.printSchema()\n",
    "    print('-----------------------------')\n",
    "    print('Getting and check newest data')\n",
    "    print('-----------------------------')\n",
    "    df = df\\\n",
    "        .where(col('ts')>= mysql_time)\n",
    "    print('-----------------------------')\n",
    "    print('Processing Cassandra Output')\n",
    "    print('-----------------------------')\n",
    "    cassandra_output = process_cassandra_data(df)\n",
    "    print('-----------------------------')\n",
    "    print('Merge Company Data')\n",
    "    print('-----------------------------')\n",
    "    company = retrieve_company_data()\n",
    "    print('-----------------------------')\n",
    "    print('Finalizing Output')\n",
    "    print('-----------------------------')\n",
    "    final_output = cassandra_output\\\n",
    "        .join(company,'job_id','full')\\\n",
    "        .drop(company.group_id)\\\n",
    "        .drop(company.campaign_id)\\\n",
    "        .withColumn('latest_update_time', current_timestamp())\n",
    "    print('-----------------------------')\n",
    "    print('Import Output to MySQL')\n",
    "    print('-----------------------------')\n",
    "    import_to_mysql(final_output, db_table='events')\n",
    "    return print('Task Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_time_cassandra():\n",
    "    cassandra_latest_time = data.agg({'ts':'max'}).take(1)[0][0]\n",
    "    return cassandra_latest_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mysql_latest_time():    \n",
    "    sql = \"\"\"(select max(latest_update_time) from events) data\"\"\"\n",
    "    mysql_time = spark.read.format('jdbc')\\\n",
    "        .options(url=url, driver=driver, dbtable=sql, user=user, password=password).load()\n",
    "    mysql_time = mysql_time.take(1)[0][0]\n",
    "    if mysql_time is None:\n",
    "        mysql_latest = '1998-01-01 23:59:59'\n",
    "    else :\n",
    "        mysql_latest = mysql_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return mysql_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:16:14\n",
      "The host is  localhost\n",
      "The port using is  3306\n",
      "The db using is  study_de\n",
      "-----------------------------\n",
      "Retrieving and selecting data from Cassandra\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Processing data from Cassandra\n",
      "-----------------------------\n",
      "root\n",
      " |-- create_time: string (nullable = false)\n",
      " |-- ts: string (nullable = true)\n",
      " |-- job_id: string (nullable = true)\n",
      " |-- custom_track: string (nullable = true)\n",
      " |-- bid: integer (nullable = true)\n",
      " |-- campaign_id: integer (nullable = true)\n",
      " |-- group_id: string (nullable = true)\n",
      " |-- publisher_id: integer (nullable = true)\n",
      "\n",
      "-----------------------------\n",
      "Getting and check newest data\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Processing Cassandra Output\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Merge Company Data\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Finalizing Output\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Import Output to MySQL\n",
      "-----------------------------\n",
      "Data imported successfully\n",
      "Task Finished\n",
      "Job takes 184.455121 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.40958 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.334361 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.35604 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.324757 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.33348 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.380537 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.429441 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.290601 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.480651 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.404042 seconds to execute\n",
      "Cassandra latest time is 2023-07-20 15:24:09\n",
      "MySQL latest time is 2023-07-20 15:26:24\n",
      "No new data found\n",
      "Job takes 0.370174 seconds to execute\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-6eb1a2a81bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mexecution_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Job takes {} seconds to execute'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecution_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True :\n",
    "    start_time = datetime.now()\n",
    "    cassandra_time = get_latest_time_cassandra()\n",
    "    print(f'Cassandra latest time is {cassandra_time}')\n",
    "    mysql_time = get_mysql_latest_time()\n",
    "    print(f'MySQL latest time is {mysql_time}')\n",
    "    if cassandra_time > mysql_time : \n",
    "        main_task(mysql_time)\n",
    "    else :\n",
    "        print(\"No new data found\")\n",
    "    end_time = datetime.now()\n",
    "    execution_time = (end_time - start_time).total_seconds()\n",
    "    print('Job takes {} seconds to execute'.format(execution_time))\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
